{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/dataset\" # Folder containing pairs of .png/.jpg/.jpeg images and .txt files describing the image\n",
    "checkpoint_path = \"/content/checkpoints\" # Folder to save/load the checkpoints\n",
    "output_image_path = \"/content/images\" # Folder to save a generated image\n",
    "checkpoint_rate = 50 # Save checkpoint file every x iterations\n",
    "enable_inference = True # Enable inference during training?\n",
    "enable_inference_show = False # Enable showing inference results during training?\n",
    "inference_keep_output_image = True # Enable to keep infrence image outputs from being overwritten, useful for visual progress of training \n",
    "inference_rate = 4 # Run inference every x steps, recommended to set this to the same value as checkpoint_rate so you have a inference output for last checkpoint, setting this to a low value will slow down training\n",
    "inference_prompt = \"Danger High Voltage Label\" # Prompt used by inference() to generate image\n",
    "timesteps = 100 # Steps to run while inferencing, increase for higher quality but slower processing\n",
    "epochs = 2 # For each unet\n",
    "batch_ss = 12 # The real batch size\n",
    "batch_s =  6 # Batch size to grad accum when using trainer class, saves from OOM, real batch size should be bigger than this\n",
    "use_ema = False # Use EMA when using trainer class? If use, sampling will result just a noise\n",
    "meth = \"trainer\" # Which method to use? \"imagen\" or \"trainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "import torch, glob\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_emb_tensor(files):\n",
    "    texts = []\n",
    "    for i in files:\n",
    "        f = open(i + \"txt\", \"r\")\n",
    "        texts.append(f.read())\n",
    "        f.close()\n",
    "    text_embeds, text_masks = t5_encode_text(texts, name = 'google/t5-v1_1-base')\n",
    "    text_embeds, text_masks = map(lambda t: t.to('cuda:0'), (text_embeds, text_masks))\n",
    "    return text_embeds, text_masks\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "#thanks KyriaAnnwyn\n",
    "def get_images_tensor(files):\n",
    "    img_arr = []\n",
    "    transforms = torch.nn.Sequential(\n",
    "        T.Resize(image_size),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.CenterCrop(image_size),\n",
    "        T.ConvertImageDtype(torch.float)\n",
    "    )\n",
    "    exts = [\"jpg\", \"jpeg\", \"png\"]\n",
    "    for i in files:\n",
    "        fileName = None\n",
    "        for ext in exts:\n",
    "            if os.path.isfile(i + ext):\n",
    "                fileName = i + ext\n",
    "                break\n",
    "        if fileName == None:\n",
    "            raise ValueError(f\"Could not find image for {i}\")\n",
    "        img_arr.append((transforms(torchvision.io.read_image(fileName, torchvision.io.ImageReadMode.RGB)) * 2 - 1).unsqueeze(0))\n",
    "    img_embeds = torch.cat((img_arr), dim=0).to('cuda')\n",
    "    return img_embeds\n",
    "    \n",
    "current_checkpoint_path = os.path.join(checkpoint_path, \"checkpoint.pt\")\n",
    "\n",
    "def saveCheckpoint(trainer: ImagenTrainer):\n",
    "    print(\"Saving checkpoint\")\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    new_checkpoint_path = os.path.join(checkpoint_path, f\"checkpoint-{current_datetime}.pt\")\n",
    "    trainer.save(new_checkpoint_path)\n",
    "    shutil.copyfile(new_checkpoint_path, current_checkpoint_path)\n",
    "\n",
    "def loadCheckpoint(trainer: ImagenTrainer):\n",
    "    try:\n",
    "        trainer.load(current_checkpoint_path)\n",
    "        print(\"Loaded checkpoint\")\n",
    "    except: pass\n",
    "\n",
    "def inference(trainer: ImagenTrainer, show: bool, keep_image: bool, average = None):\n",
    "    # now you can sample an image based on the text embeddings from the cascading ddpm\n",
    "    texts = [inference_prompt]\n",
    "    print(texts)\n",
    "    img = trainer.sample(texts, cond_scale = 2.)\n",
    "\n",
    "    if show:\n",
    "        # Show the generated image\n",
    "        print(img.shape)\n",
    "        print(img[0].shape)\n",
    "        image = T.ToPILImage()(img[0]).convert(\"RGB\")\n",
    "        image.show() #returns None but expected just display image\n",
    "        plt.imshow(image) #returns image with plt\n",
    "    \n",
    "    # Save image\n",
    "    image = img[0]\n",
    "\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if keep_image:\n",
    "        output_image_filename = os.path.join(output_image_path, f'output-{current_datetime}-{average}.png')\n",
    "    else:\n",
    "        output_image_filename = os.path.join(output_image_path, 'output.png')\n",
    "\n",
    "    save_image(image, output_image_filename)\n",
    "    print(f'Inference image saved to: {output_image_filename}')\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (64, 256),\n",
    "    beta_schedules = ('cosine', 'linear'),\n",
    "    timesteps = timesteps,\n",
    "    cond_drop_prob = 0.5\n",
    ").cuda()\n",
    "\n",
    "trainer = ImagenTrainer(imagen, use_ema = use_ema)\n",
    "\n",
    "#feed images into imagen, training each unet in the cascade\n",
    "#try to load last ckpt\n",
    "loadCheckpoint(trainer)\n",
    "\n",
    "if not os.path.exists(output_image_path):\n",
    "    os.makedirs(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (this can be skipped if running inference on an existing checkpoint)\n",
    "\n",
    "a = glob.glob(f\"{dataset_path}/*.txt\")\n",
    "last_i = 0\n",
    "batches = []\n",
    "batch_ss = batch_ss\n",
    "temp = 0\n",
    "st = ''\n",
    "for i, na in enumerate(a):\n",
    "  if i % batch_ss == 0:\n",
    "    last_i+=1\n",
    "  \n",
    "  st = st + na[:-3] + ' '\n",
    "  \n",
    "  \n",
    "  if temp != last_i:\n",
    "      if st != '': batches.append(st)\n",
    "      st = ''\n",
    "  temp = last_i\n",
    "if st != '': batches.append(st)\n",
    "st = batches[0]\n",
    "batches.pop(0)\n",
    "if batch_ss!= 1: batches[-1] += st \n",
    "\n",
    "\n",
    "\n",
    "for i in (1, 2):\n",
    "  l_arr = []\n",
    "  for eps in range(1, epochs+1):\n",
    "      \n",
    "      with tqdm(total=len(batches)) as pbar:\n",
    "          for step, e in enumerate(batches):\n",
    "              \n",
    "              batch = batches[step].split(' ')[:-1]\n",
    "              text_embeds, text_masks = get_emb_tensor(batch)\n",
    "              images = get_images_tensor(batch)\n",
    "\n",
    "              if meth == 'imagen':\n",
    "                loss = imagen(images, text_embeds = text_embeds, text_masks = text_masks, unet_number = i)\n",
    "                loss.backward()\n",
    "              else:\n",
    "                loss = trainer(images, text_embeds = text_embeds, text_masks = text_masks, unet_number = i, max_batch_size = batch_s)\n",
    "                trainer.update(unet_number = i)\n",
    "                \n",
    "              l_arr.append(loss)\n",
    "              avg_loss = round((sum(l_arr)/len(l_arr)), 5)\n",
    "              if step % checkpoint_rate == 0 and step !=0 and not math.isnan(loss):\n",
    "                  saveCheckpoint(trainer)\n",
    "              if step % inference_rate == 0 and step !=0 and not math.isnan(loss) and enable_inference == True:\n",
    "                  inference(trainer, enable_inference_show, inference_keep_output_image, avg_loss)\n",
    "              pbar.set_description(f'Unet Num: {i}  Epoch: {eps}  Loss: {loss} Avg Loss: {avg_loss}')\n",
    "              pbar.update()\n",
    "      if not math.isnan(loss): saveCheckpoint(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "\n",
    "inference(trainer, enable_inference_show, False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
